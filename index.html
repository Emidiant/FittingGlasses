<html>
<head>
    <title>threejs - models</title>
    <link href="style.css" rel="stylesheet">
</head>
<body>
    <script src="libs/face-api.min.js"></script>
    <video id="video" width="720" height="560" autoplay muted></video>
    <canvas id="canvas" class="d-none"></canvas>


    <canvas id="myCanvas"></canvas>
    <script src="libs/three.js"></script>
    <script src="libs/GLTFLoader.js"></script>

    <script>
        const video = document.getElementById('video')

        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('models/tiny_face_detector_model-weights_manifest.json'),
            faceapi.nets.faceLandmark68Net.loadFromUri('models/face_landmark_68_model-weights_manifest.json'),
            faceapi.nets.faceRecognitionNet.loadFromUri('models/face_recognition_model-weights_manifest.json')
        ]).then(startVideo)

        function startVideo() {
            navigator.getUserMedia(
                { video: {} },
                stream => video.srcObject = stream,
                err => console.error(err)
            )
        }

        var renderer,
            scene,
            camera,
            myCanvas = document.getElementById('myCanvas');

        //RENDERER
        renderer = new THREE.WebGLRenderer({
            canvas: myCanvas,
            antialias: true,
            transparent: true
        });
        renderer.setClearColor(0x000000, 0);
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(720, 560);

        //CAMERA
        camera = new THREE.PerspectiveCamera(50, window.innerWidth/window.innerHeight, 0.01, 5000);
        // camera.rotation.y = 45/180*Math.Pi;
        // camera.position.x = 800;
        camera.position.y = 30;
        camera.position.z = 70;

        //SCENE
        scene = new THREE.Scene();
        // video = document.getElementById( 'video' );


        var vidTexture = new THREE.VideoTexture(video);

        scene.background = vidTexture;


        //LIGHTS
        var light = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(light);

        var light2 = new THREE.PointLight(0xffffff, 0.5);
        scene.add(light2);

        var loader = new THREE.GLTFLoader();

        loader.load('glasses_models/vuzix.glb', handle_load);

        var mesh;

        function handle_load(gltf) {

            console.log(gltf);
            mesh = gltf.scene;
            console.log(mesh.children[0]);
            mesh.children[0].material = new THREE.MeshLambertMaterial();
            scene.add( mesh );
            mesh.position.z = -10;
        }


        //RENDER LOOP
        var delta = 0;
        var prevTime = Date.now();

        function render(x, y) {
            if (mesh) {
                mesh.position.y = y-260;
                mesh.position.x = x-300;  // необходимо разобраться с координатами
                console.log("mesh roration" + x + " " + y)
            }
            renderer.render(scene, camera);
            // requestAnimationFrame(render);
        }

        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video)
            document.body.append(canvas)
            const displaySize = { width: video.width, height: video.height }
            faceapi.matchDimensions(canvas, displaySize)

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks()
                // const detections = await faceapi.detectFaceLandmarks(video)
                const resizedDetections = faceapi.resizeResults(detections, displaySize)
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
                // faceapi.draw.drawDetections(canvas, resizedDetections)
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)


                const landmarks = await faceapi.detectFaceLandmarks(video)
                if (landmarks) {
                    const leftEye = landmarks.getLeftEye()
                    const rightEye = landmarks.getRightEye()
                    const jawOutline = landmarks.getJawOutline()
                    console.log("Left Eye landmarks ===========>" + Math.round(leftEye[0].x) + " " + Math.round(leftEye[0].y));
                    // console.log("Right Eye landmarks ===========>" + JSON.stringify(rightEye));

                    render(Math.round(leftEye[0].x), Math.round(leftEye[0].y));
                }

            }, 200)


        })
    </script>



</body>
</html>
